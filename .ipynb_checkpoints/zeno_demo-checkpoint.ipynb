{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHtaPysVSNZN"
   },
   "source": [
    "# Step 1 - Install the required dependencies and make sure the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APS6D3eiSAR_"
   },
   "outputs": [],
   "source": [
    "!pip install zenoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRrMiMnLV9xY",
    "outputId": "5193e819-f2cb-4032-99df-ced1ea7b4191",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Load a dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "df = pd.DataFrame(ds['test']).head(500)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['roberta'] = [r[0]['label'] for r in results]\n",
    "df['roberta_score'] = [r[0]['score'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LYTinn/finetuning-sentiment-model-tweet-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt2'] = [r[0]['label'] for r in results]\n",
    "df['gpt2_score'] = [r[0]['score'] for r in results]\n",
    "\n",
    "def label_map(x):\n",
    "    if x == 'LABEL_0':\n",
    "        return 'negative'\n",
    "    elif x == 'LABEL_1':\n",
    "        return 'neutral'\n",
    "    elif x == 'LABEL_2':\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['gpt2'] = df['gpt2'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Pre-processing data and add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(x):\n",
    "    if x == 0:\n",
    "        return 'negative'\n",
    "    elif x == 1:\n",
    "        return 'neutral'\n",
    "    elif x == 2:\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input_length\"] = df[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Start Zeno for interactive slicing\n",
    "\n",
    "Create 5 slices in the Zeno interface and derive meaningful insights\n",
    "1. Tweets with hashtags\n",
    "2. Tweets with strong positive words (e.g., love) -- you can determine the exact words\n",
    "3. [YOUR CHOICE]\n",
    "4. [YOUR CHOICE]\n",
    "5. [YOUR CHOICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zeno import zeno\n",
    "\n",
    "from zeno.api import model, distill, metric\n",
    "from zeno.api import ModelReturn, MetricReturn, DistillReturn, ZenoOptions\n",
    "\n",
    "@model\n",
    "def load_model(model_name):\n",
    "    \n",
    "    def pred(df, ops: ZenoOptions):\n",
    "        out = df[model_name]\n",
    "        return ModelReturn(model_output=out)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@distill\n",
    "def label_match(df, ops: ZenoOptions):\n",
    "    results = (df[ops.label_column] == df[ops.output_column]).to_list()\n",
    "    return DistillReturn(distill_output=results)\n",
    "\n",
    "@metric\n",
    "def accuracy(df, ops: ZenoOptions):\n",
    "    avg = df[ops.distill_columns[\"label_match\"]].mean()\n",
    "    return MetricReturn(metric=avg)\n",
    "\n",
    "zeno({\n",
    "    \"metadata\": df, # Pandas DataFrame with a row for each instance\n",
    "    \"view\": \"text-classification\", # The type of view for this data/task\n",
    "    \"data_column\": \"text\", \n",
    "    \"label_column\": \"label\",\n",
    "    \"functions\": [load_model, label_match, accuracy],\n",
    "    \"models\": [\"roberta\", \"gpt2\"],\n",
    "    \"port\": 8231\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Write down three addition data slices you want to create but do not have the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: \n",
    "- I want to create a slice on tweets using slangs\n",
    "- I want to create a slice on non-English tweets (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
